#!/usr/bin/env python3
"""
Smart Interactive mode for SAGA Biography Generation System.
Uses Coordinator Agent to dynamically control the workflow.
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime
import re
import json
import warnings

# Suppress AutoGen warnings
warnings.filterwarnings('ignore', message='Missing required field.*structured_output.*')

# Add src to Python path
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))

from autogen_core.models import UserMessage
from config.settings import settings
from src.models.client_manager import model_manager
from src.tools.history_analyzer import event_extractor, contextualizer
from src.tools.quality_evaluator import quality_critic, hero_evaluator
from src.utils.file_manager import file_manager


class SmartInteractiveSession:
    """Smart interactive session with dynamic coordinator control."""
    
    def __init__(self):
        self.interview_content = ""
        self.interview_dialogue = []
        self.biography = ""
        self.biography_versions = []  # Track all versions
        self.quality_result = {}
        self.hero_journey_result = {}
        self.historical_context = {}
        self.current_phase = "starting"
        self.conversation_history = ""
        self.extracted_anchors = None
        
        # Action history to prevent loops
        self.action_history = []  # List of (iteration, action, reasoning)
        
    def display_header(self):
        """Display system header."""
        print("\n" + "=" * 80)
        print("ğŸ­ SAGA Biography Generation System - Smart Interactive Mode")
        print("=" * 80)
        print("âœ¨ AI Coordinator dynamically manages the biography creation process")
        print("ğŸ§  Coordinator | Interview Agent | History Researcher | Writer | Evaluator")
        print("-" * 80)
    
    def display_phase(self, phase: str, description: str):
        """Display current phase."""
        phase_icons = {
            "interview": "ğŸ¤",
            "history": "ğŸ“š", 
            "writing": "âœï¸",
            "quality": "ğŸ”",
            "refine": "ğŸ”„",
            "completed": "ğŸ‰"
        }
        icon = phase_icons.get(phase, "âš¡")
        self.current_phase = phase
        print(f"\n{icon} ã€{phase.upper()} PHASEã€‘{description}")
        print("-" * 60)
    
    def display_agent_action(self, agent_name: str, action: str, content: str = ""):
        """Display agent action with timestamp."""
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"\n[{timestamp}] ğŸ¤– {agent_name} | {action}")
        if content:
            if len(content) > 500:
                print(f"   ğŸ“ {content[:500]}...")
            else:
                print(f"   ğŸ“ {content}")
    
    def display_thinking(self, agent_name: str, thinking_content: str):
        """Display agent's thinking process."""
        print(f"\nğŸ’­ {agent_name} çš„æ€è€ƒè¿‡ç¨‹:")
        print("-" * 50)
        print(thinking_content)
        print("-" * 50)
    
    def display_coordinator_decision(self, decision: dict):
        """Display coordinator's decision."""
        print(f"\nğŸ§  Coordinator å†³ç­–:")
        print("-" * 50)
        print(f"   ä¸‹ä¸€æ­¥è¡ŒåŠ¨: {decision.get('next_action', 'unknown')}")
        print(f"   åŸå› : {decision.get('reasoning', 'N/A')}")
        if decision.get('parameters'):
            print(f"   å‚æ•°: {decision.get('parameters')}")
        print("-" * 50)
    
    def display_search_results(self, query: str, results: list):
        """Display search results with sources."""
        print(f"\nğŸ” æœç´¢æŸ¥è¯¢: {query}")
        print("   æœç´¢ç»“æœ:")
        for i, result in enumerate(results[:3], 1):
            title = result.get('title', 'No title')
            url = result.get('url', 'No URL')
            content = result.get('content', '')
            print(f"\n   {i}. {title}")
            print(f"      ğŸ”— {url}")
            if content:
                summary = content[:150] + "..." if len(content) > 150 else content
                print(f"      ğŸ“„ {summary}")
    
    async def coordinator_decide_next_action(self) -> dict:
        """Coordinator decides what to do next."""
        coordinator_client = model_manager.create_client()
        
        # Get recent action history
        recent_actions = self.action_history[-10:] if self.action_history else []
        action_summary = "\n".join([
            f"  è¿­ä»£{iter}: {action} - {reason[:50]}..."
            for iter, action, reason in recent_actions
        ]) if recent_actions else "  å°šæœªæ‰§è¡Œä»»ä½• action"
        
        # Count action frequencies
        action_counts = {}
        for _, action, _ in recent_actions:
            action_counts[action] = action_counts.get(action, 0) + 1
        
        # Check if stuck in a loop
        last_3_actions = [action for _, action, _ in recent_actions[-3:]]
        is_repeating = len(set(last_3_actions)) == 1 and len(last_3_actions) == 3
        
        # Build rich context for coordinator
        context = f"""å½“å‰çŠ¶æ€å¿«ç…§:
- å½“å‰é˜¶æ®µ: {self.current_phase}
- è®¿è°ˆè½®æ•°: {len(self.interview_dialogue) // 2}
- è®¿è°ˆå†…å®¹: {len(self.interview_content)} å­—ç¬¦
- è‡ªä¼ ç‰ˆæœ¬: {len(self.biography_versions)} ä¸ª
- å·²æœ‰è‡ªä¼ : {'æ˜¯' if self.biography else 'å¦'} ({len(self.biography)} å­—)
- è´¨é‡è¯„ä¼°: {'æ˜¯' if self.quality_result else 'å¦'} ({self.quality_result.get('overall_score', 0):.1f}/10)
- äº‹ä»¶æå–: {'æ˜¯' if self.extracted_anchors else 'å¦'}
- å†å²ç ”ç©¶: {'æ˜¯' if self.historical_context else 'å¦'}

ğŸ“Š æœ€è¿‘æ‰§è¡Œçš„ Actions (æœ€è¿‘10æ¬¡):
{action_summary}

âš ï¸ Action é¢‘ç‡ç»Ÿè®¡:
{', '.join([f'{action}({count}æ¬¡)' for action, count in action_counts.items()]) if action_counts else 'æ— '}

ğŸš¨ è­¦å‘Š: {'æ­£åœ¨é‡å¤åŒä¸€ä¸ªactionï¼å¿…é¡»æ¢ä¸€ä¸ªï¼' if is_repeating else 'è¿è¡Œæ­£å¸¸'}

ğŸ“ æœ€è¿‘3è½®å¯¹è¯:
{self.conversation_history[-800:] if self.conversation_history else 'å°šæœªå¼€å§‹'}

ğŸ“– å½“å‰è‡ªä¼ å†…å®¹ï¼ˆå¦‚æœ‰ï¼‰:
{self.biography[:300] + '...' if len(self.biography) > 300 else self.biography if self.biography else 'å°šæœªç”Ÿæˆ'}

ğŸ¯ å…³é”®ä¿¡æ¯ç‚¹:
- ç”¨æˆ·æœ€åä¸€å¥è¯: {self.interview_dialogue[-1]['content'][:100] if self.interview_dialogue else 'æ— '}
"""
        
        prompt = f"""{context}

ä½ æ˜¯SAGAç³»ç»Ÿçš„æ™ºèƒ½åè°ƒè€…ï¼ˆCoordinatorï¼‰ï¼Œè´Ÿè´£åè°ƒå¤šä¸ª AI agents å’Œ tools å®Œæˆè‡ªä¼ åˆ›ä½œã€‚

ğŸ“‹ å¯ç”¨çš„ Agents å’Œ Tools:

1. **Interview Agent** (è®¿è°ˆä»£ç†)
   - ä½œç”¨ï¼šä¸ç”¨æˆ·å¯¹è¯ï¼Œæ”¶é›†äººç”Ÿæ•…äº‹
   - èƒ½åŠ›ï¼šæå‡ºæ·±å…¥é—®é¢˜ï¼Œå¼•å¯¼ç”¨æˆ·åˆ†äº«
   - è¾“å‡ºï¼šè®¿è°ˆå¯¹è¯è®°å½•
   
2. **Event Extractor** (äº‹ä»¶æå–å™¨)
   - ä½œç”¨ï¼šä»è®¿è°ˆä¸­æå–å†å²äº‹ä»¶é”šç‚¹
   - èƒ½åŠ›ï¼šè¯†åˆ«æ—¶é—´ã€åœ°ç‚¹ã€å†å²äº‹ä»¶
   - è¾“å‡ºï¼šç»“æ„åŒ–çš„å†å²äº‹ä»¶åˆ—è¡¨
   - Tool: `event_extractor.extract_historical_anchors()`
   
3. **History Contextualizer** (å†å²èƒŒæ™¯ç ”ç©¶å™¨)
   - ä½œç”¨ï¼šæœç´¢å’Œåˆ†æå†å²èƒŒæ™¯
   - èƒ½åŠ›ï¼šä½¿ç”¨ Tavily API æœç´¢äº’è”ç½‘
   - è¾“å‡ºï¼šç›¸å…³å†å²äº‹ä»¶çš„è¯¦ç»†èƒŒæ™¯
   - Tool: `contextualizer.contextualize_events()`
   
4. **Biography Writer** (è‡ªä¼ ä½œè€…)
   - ä½œç”¨ï¼šåŸºäºè®¿è°ˆå’Œå†å²èƒŒæ™¯åˆ›ä½œè‡ªä¼ 
   - èƒ½åŠ›ï¼šè¿ç”¨è‹±é›„ä¹‹æ—…æ¡†æ¶ç¼–ç»‡æ•…äº‹
   - è¾“å‡ºï¼šå®Œæ•´çš„è‡ªä¼ æ–‡æœ¬
   - ä½¿ç”¨ï¼šé€šè¿‡ model_client è°ƒç”¨ AI åˆ›ä½œ
   
5. **Quality Evaluator** (è´¨é‡è¯„ä¼°å™¨)
   - ä½œç”¨ï¼šè¯„ä¼°è‡ªä¼ è´¨é‡å’Œè‹±é›„ä¹‹æ—…å¥‘åˆåº¦
   - èƒ½åŠ›ï¼šå¤šç»´åº¦è¯„åˆ†ï¼ˆå™äº‹ã€æƒ…æ„Ÿã€å†å²ã€è¯­è¨€ï¼‰
   - è¾“å‡ºï¼šè´¨é‡åˆ†æ•° (0-10) å’Œæ”¹è¿›å»ºè®®
   - Tool: `quality_critic.evaluate()`, `hero_evaluator.evaluate_biography()`

ğŸ”„ æ¨èçš„ Workflowï¼ˆçµæ´»æ‰§è¡Œï¼‰:

**é˜¶æ®µ 1: ä¿¡æ¯æ”¶é›†**
```
Interview Agent (3-10è½®)
  â†“ å¦‚æœç”¨æˆ·æåˆ°å†å²äº‹ä»¶ï¼ˆå¦‚"æ–‡é©"ï¼‰
  â†“â†’ ç«‹å³è°ƒç”¨ History Contextualizer
  â†“ ç»§ç»­ Interview
  â†“ ä¿¡æ¯å……è¶³æ—¶
  â†“
ç»“æŸè®¿è°ˆ
```

**é˜¶æ®µ 2: ä¿¡æ¯å¤„ç†**
```
è°ƒç”¨ Event Extractor
  â†’ æå–å†å²äº‹ä»¶é”šç‚¹
  
å¦‚æœæœ‰æ–°äº‹ä»¶éœ€è¦èƒŒæ™¯
  â†’ è°ƒç”¨ History Contextualizer
  â†’ æœç´¢å†å²èƒŒæ™¯
```

**é˜¶æ®µ 3: åˆ›ä½œä¸ä¼˜åŒ–**
```
è°ƒç”¨ Biography Writer
  â†’ åˆ›ä½œåˆç¨¿
  â†“
è°ƒç”¨ Quality Evaluator
  â†’ è¯„ä¼°è´¨é‡
  â†“
å¦‚æœåˆ†æ•° < 8
  â†’ è°ƒç”¨ Biography Writerï¼ˆå¸¦æ”¹è¿›å»ºè®®ï¼‰
  â†’ ä¼˜åŒ–è‡ªä¼ 
  â†’ é‡æ–°è¯„ä¼°
  â†“
è´¨é‡è¾¾æ ‡ â†’ å®Œæˆ
```

ğŸ¯ å¯ç”¨ Actions åŠå¯¹åº”çš„ Agent/Tool:

1. **continue_interview** 
   - Agent: Interview Agent
   - åœºæ™¯ï¼šä¿¡æ¯ä¸è¶³ï¼Œéœ€è¦æ›´å¤šç»†èŠ‚
   - åœºæ™¯ï¼šç”¨æˆ·åˆ†äº«ä¸å¤Ÿæ·±å…¥
   - åœºæ™¯ï¼šé‡è¦é¢†åŸŸï¼ˆç«¥å¹´ã€å·¥ä½œã€è½¬æŠ˜ç‚¹ï¼‰è¿˜æœªæ¶‰åŠ
   - è¯¢é—®ç­–ç•¥ï¼šå¼€æ”¾å¼é—®é¢˜ â†’ å…·ä½“ç»†èŠ‚ â†’ æƒ…æ„Ÿä½“éªŒ

2. **end_interview**
   - æ ‡è®°è®¿è°ˆç»“æŸ
   - åœºæ™¯ï¼šå·²æ”¶é›†è¶³å¤Ÿä¿¡æ¯ï¼ˆé€šå¸¸5-10è½®ï¼‰
   - åœºæ™¯ï¼šç”¨æˆ·è¡¨ç¤ºæƒ³ç»“æŸ
   - åœºæ™¯ï¼šè¦†ç›–äº†ä¸»è¦äººç”Ÿé˜¶æ®µ

3. **extract_events**
   - Tool: Event Extractor (event_extractor.extract_historical_anchors)
   - åœºæ™¯ï¼šè®¿è°ˆä¸­æåˆ°äº†æ—¶é—´ã€åœ°ç‚¹ã€å†å²äº‹ä»¶
   - åœºæ™¯ï¼šéœ€è¦è¯†åˆ«å¯ç ”ç©¶çš„å†å²èƒŒæ™¯
   - åœºæ™¯ï¼šå‡†å¤‡åˆ›ä½œå‰çš„ä¿¡æ¯æ•´ç†
   - âš¡ æå–ä¸€æ¬¡å³å¯ï¼Œä¸éœ€è¦é‡å¤

4. **research_history**
   - Tool: History Contextualizer (contextualizer.contextualize_events)
   - è§¦å‘æ¡ä»¶ï¼š
     * ç”¨æˆ·æåˆ°å…·ä½“å†å²äº‹ä»¶ï¼ˆå¦‚"æ–‡é©"ã€"ä¸‹å²—æ½®"ã€"æ”¹é©å¼€æ”¾"ï¼‰
     * æåˆ°ç‰¹å®šå¹´ä»£ï¼ˆå¦‚"90å¹´ä»£"ã€"2008å¹´"ï¼‰
     * Event Extractor è¯†åˆ«å‡ºå†å²é”šç‚¹
   - èƒ½åŠ›ï¼šä½¿ç”¨ Tavily API æœç´¢äº’è”ç½‘è·å–å†å²èƒŒæ™¯
   - âš¡ å¯ä»¥éšæ—¶è§¦å‘ï¼ä¸éœ€è¦ç­‰è®¿è°ˆç»“æŸ
   - âš¡ æœç´¢ä¸€æ¬¡å³å¯ï¼Œä¸éœ€è¦é‡å¤ï¼ˆé™¤éæœ‰æ–°äº‹ä»¶ï¼‰

5. **write_biography**
   - Agent: Biography Writer (ä½¿ç”¨ AI model)
   - å‰ç½®æ¡ä»¶ï¼š
     * æœ‰è¶³å¤Ÿè®¿è°ˆå†…å®¹ï¼ˆé€šå¸¸â‰¥5è½®ï¼‰
     * æœ€å¥½æœ‰å†å²èƒŒæ™¯ï¼ˆä¸æ˜¯å¿…é¡»ï¼‰
   - èƒ½åŠ›ï¼šè¿ç”¨è‹±é›„ä¹‹æ—…æ¡†æ¶ç¼–ç»‡ä¸ªäººæ•…äº‹
   - å¯ä»¥å…ˆå†™åˆç¨¿ï¼Œåç»­ç»§ç»­å®Œå–„

6. **evaluate_quality**
   - Tool: Quality Evaluator (quality_critic + hero_evaluator)
   - åœºæ™¯ï¼šæœ‰è‡ªä¼ å†…å®¹éœ€è¦è¯„ä¼°
   - è¾“å‡ºï¼šè´¨é‡åˆ†æ•°(0-10) + è‹±é›„ä¹‹æ—…å¥‘åˆåº¦ + æ”¹è¿›å»ºè®®
   - è¯„ä¼°ç»´åº¦ï¼šå™äº‹è´¨é‡ã€æƒ…æ„Ÿæ·±åº¦ã€å†å²èåˆã€è¯­è¨€è¡¨è¾¾

7. **refine_biography**
   - Agent: Biography Writer (å¸¦æ”¹è¿›å»ºè®®)
   - è§¦å‘æ¡ä»¶ï¼šè´¨é‡è¯„ä¼° < 8åˆ†
   - è¾“å…¥ï¼šåŸè‡ªä¼  + è´¨é‡è¯„ä¼°çš„æ”¹è¿›å»ºè®®
   - è¾“å‡ºï¼šä¼˜åŒ–åçš„æ–°ç‰ˆæœ¬

8. **complete**
   - å®Œæˆæ•´ä¸ªæµç¨‹
   - æ¡ä»¶ï¼šè´¨é‡è¾¾æ ‡ï¼ˆâ‰¥8åˆ†ï¼‰æˆ–å·²å¤šè½®ä¼˜åŒ–

ğŸ§  æ™ºèƒ½å†³ç­–åŸåˆ™:

1. **ç†è§£ Agent/Tool çš„ä½œç”¨**ï¼š
   - Interview Agent â†’ æ”¶é›†ä¿¡æ¯ï¼ˆå¯¹è¯ï¼‰
   - Event Extractor â†’ åˆ†æä¿¡æ¯ï¼ˆæå–ç»“æ„ï¼‰
   - History Contextualizer â†’ è¡¥å……èƒŒæ™¯ï¼ˆæœç´¢ï¼‰
   - Biography Writer â†’ åˆ›ä½œå†…å®¹ï¼ˆå†™ä½œï¼‰
   - Quality Evaluator â†’ è¯„ä¼°è´¨é‡ï¼ˆæ‰“åˆ†ï¼‰

2. **ååº”å¼è§¦å‘**ï¼š
   - ç”¨æˆ·æåˆ°"æ–‡é©" â†’ ç«‹å³ research_history (è°ƒç”¨ History Contextualizer)
   - ç”¨æˆ·è¯´"å°±è¿™äº›" â†’ è€ƒè™‘ end_interview
   - å‘ç°ä¿¡æ¯ç©ºç¼º â†’ continue_interview (è°ƒç”¨ Interview Agent)
   - è®¿è°ˆå†…å®¹ä¸°å¯Œ â†’ extract_events (è°ƒç”¨ Event Extractor)

3. **Agent è°ƒç”¨é¡ºåºæŒ‡å¼•**ï¼š
   ```
   å…¸å‹æµç¨‹:
   Interview Agent (æ”¶é›†) 
     â†’ Event Extractor (åˆ†æ)
     â†’ History Contextualizer (æœç´¢)
     â†’ Biography Writer (åˆ›ä½œ)
     â†’ Quality Evaluator (è¯„ä¼°)
     â†’ Biography Writer (ä¼˜åŒ–)
   
   çµæ´»å˜åŒ–:
   - è®¿è°ˆè¿‡ç¨‹ä¸­å¯éšæ—¶è°ƒç”¨ History Contextualizer
   - å¯ä»¥è¾¹è®¿è°ˆè¾¹æå–äº‹ä»¶
   - å¯ä»¥å…ˆå†™åˆç¨¿ï¼Œå†ç»§ç»­è®¿è°ˆè¡¥å……
   ```

4. **è´¨é‡ä¼˜å…ˆ**ï¼š
   - å®å¯å¤šé—®å‡ è½®ï¼Œç¡®ä¿ Interview Agent æ”¶é›†è¶³å¤Ÿä¿¡æ¯
   - Quality Evaluator è¯„åˆ† < 8 â†’ å¿…é¡»è°ƒç”¨ Biography Writer ä¼˜åŒ–
   - æœ‰ç–‘é—®å°±ç»§ç»­ Interview

5. **é¿å…é‡å¤è°ƒç”¨**ï¼š
   - Event Extractor: æå–ä¸€æ¬¡å³å¯
   - History Contextualizer: æœç´¢ä¸€æ¬¡å³å¯ï¼ˆé™¤éæœ‰æ–°äº‹ä»¶ï¼‰
   - Quality Evaluator: è¯„ä¼°ååº”è¯¥ä¼˜åŒ–æˆ–å®Œæˆï¼Œä¸æ˜¯å†è¯„ä¼°

âš ï¸ å…³é”®çº¦æŸ:
1. **ç¦æ­¢è¿ç»­é‡å¤åŒä¸€ä¸ª action**
   - å¦‚æœåˆšæ‰§è¡Œäº† research_historyï¼Œä¸‹æ¬¡ä¸è¦å†é€‰ research_history
   - å¦‚æœåˆšæ‰§è¡Œäº† extract_eventsï¼Œä¸‹æ¬¡ä¸è¦å†é€‰ extract_events
   - æŸ¥çœ‹"æœ€è¿‘æ‰§è¡Œçš„ Actions"é¿å…é‡å¤

2. **å„ action é€šå¸¸åªéœ€æ‰§è¡Œä¸€æ¬¡**
   - extract_events: æå–ä¸€æ¬¡å³å¯ï¼Œä¸éœ€è¦é‡å¤
   - research_history: æœç´¢ä¸€æ¬¡å³å¯ï¼Œä¸éœ€è¦é‡å¤æœç´¢
   - evaluate_quality: è¯„ä¼°ååº”è¯¥ refine æˆ– completeï¼Œä¸æ˜¯å†è¯„ä¼°
   
3. **æ­£ç¡®çš„æµç¨‹æ¨è¿›**
   - extract_events â†’ research_history â†’ write_biography
   - ä¸æ˜¯ extract_events â†’ extract_events â†’ extract_events
   - ä¸æ˜¯ research_history â†’ research_history â†’ research_history

4. **å¦‚æœå‘ç°é‡å¤**
   - ç«‹å³é€‰æ‹©ä¸åŒçš„ action
   - æ¨è¿›åˆ°ä¸‹ä¸€ä¸ªé˜¶æ®µ
   - ä¾‹å¦‚ï¼šå·²ç» research_history â†’ åº”è¯¥ write_biography æˆ– continue_interview

è¯·ä»¥JSONæ ¼å¼è¿”å›å†³ç­–:
{{
  "next_action": "è¡ŒåŠ¨åç§°",
  "reasoning": "åŸºäºå½“å‰å¯¹è¯å†…å®¹å’ŒçŠ¶æ€çš„è¯¦ç»†å†³ç­–ç†ç”±",
  "trigger": "è§¦å‘è¿™ä¸ªå†³ç­–çš„å…·ä½“å†…å®¹æˆ–æ¡ä»¶",
  "confidence": 0.0-1.0
}}"""
        
        try:
            response = await coordinator_client.create(
                messages=[UserMessage(content=prompt, source="user")]
            )
            
            # Parse JSON response
            response_text = response.content.strip()
            
            # Try to extract JSON from markdown code blocks
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                response_text = json_match.group(1)
            
            decision = json.loads(response_text)
            
            # Validate decision to prevent loops
            next_action = decision.get("next_action")
            
            # Check if repeating the same action
            if len(self.action_history) >= 2:
                last_action = self.action_history[-1][1]
                second_last_action = self.action_history[-2][1] if len(self.action_history) >= 2 else None
                
                # If same action 2 times in a row, force change
                if next_action == last_action == second_last_action:
                    print(f"âš ï¸ æ£€æµ‹åˆ°è¿ç»­3æ¬¡ç›¸åŒaction '{next_action}'ï¼Œå¼ºåˆ¶åˆ‡æ¢ï¼")
                    
                    # Force different action based on state
                    if self.biography and not self.quality_result:
                        decision = {
                            "next_action": "evaluate_quality",
                            "reasoning": "æ£€æµ‹åˆ°é‡å¤actionï¼Œå¼ºåˆ¶åˆ‡æ¢åˆ°è¯„ä¼°è´¨é‡",
                            "confidence": 0.9
                        }
                    elif self.extracted_anchors and self.historical_context and not self.biography:
                        decision = {
                            "next_action": "write_biography",
                            "reasoning": "æ£€æµ‹åˆ°é‡å¤actionï¼Œå¼ºåˆ¶åˆ‡æ¢åˆ°åˆ›ä½œè‡ªä¼ ",
                            "confidence": 0.9
                        }
                    elif self.extracted_anchors and not self.historical_context:
                        decision = {
                            "next_action": "write_biography",
                            "reasoning": "æ£€æµ‹åˆ°é‡å¤researchï¼Œè·³è¿‡ç»§ç»­åˆ›ä½œ",
                            "confidence": 0.85
                        }
                    elif len(self.interview_dialogue) < 5:
                        decision = {
                            "next_action": "continue_interview",
                            "reasoning": "æ£€æµ‹åˆ°é‡å¤actionï¼Œå›åˆ°è®¿è°ˆ",
                            "confidence": 0.8
                        }
                    else:
                        # Default: move to write biography
                        decision = {
                            "next_action": "write_biography",
                            "reasoning": "æ£€æµ‹åˆ°é‡å¤actionï¼Œå¼ºåˆ¶æ¨è¿›åˆ°åˆ›ä½œé˜¶æ®µ",
                            "confidence": 0.75
                        }
            
            return decision
            
        except Exception as e:
            print(f"âš ï¸ Coordinatorå†³ç­–è§£æå¤±è´¥: {e}")
            print(f"   ä½¿ç”¨æ™ºèƒ½fallbacké€»è¾‘...")
            
            # Intelligent fallback - prioritize based on context, not rigid flow
            
            # Priority 1: If we have biography and it's low quality, improve it
            if self.biography and self.quality_result:
                if self.quality_result.get("overall_score", 0) < 8.0:
                    return {
                        "next_action": "refine_biography",
                        "reasoning": f"è‡ªä¼ è´¨é‡{self.quality_result.get('overall_score', 0):.1f}åˆ†ï¼Œéœ€è¦ä¼˜åŒ–",
                        "confidence": 0.9
                    }
                else:
                    return {
                        "next_action": "complete",
                        "reasoning": f"è´¨é‡è¾¾æ ‡({self.quality_result.get('overall_score', 0):.1f}åˆ†)ï¼Œå¯ä»¥å®Œæˆ",
                        "confidence": 0.95
                    }
            
            # Priority 2: If we have biography but no evaluation, evaluate it
            if self.biography and not self.quality_result:
                return {
                    "next_action": "evaluate_quality",
                    "reasoning": "æœ‰è‡ªä¼ ä½†æœªè¯„ä¼°ï¼Œéœ€è¦äº†è§£è´¨é‡æ°´å¹³",
                    "confidence": 0.88
                }
            
            # Priority 3: If we have enough interview data and context, write biography
            if len(self.interview_dialogue) >= 6 and (self.historical_context or len(self.interview_content) > 1500):
                if not self.biography:
                    return {
                        "next_action": "write_biography",
                        "reasoning": "è®¿è°ˆå†…å®¹å……è¶³ï¼Œå¯ä»¥å¼€å§‹åˆ›ä½œ",
                        "confidence": 0.85
                    }
            
            # Priority 4: If interview has events mentioned but not extracted
            if len(self.interview_dialogue) >= 3 and not self.extracted_anchors:
                return {
                    "next_action": "extract_events",
                    "reasoning": "è®¿è°ˆä¸­å¯èƒ½æœ‰å†å²äº‹ä»¶ï¼Œå…ˆæå–åˆ†æ",
                    "confidence": 0.75
                }
            
            # Priority 5: If we have events but no historical context
            if self.extracted_anchors and not self.historical_context:
                return {
                    "next_action": "research_history",
                    "reasoning": "å·²æå–äº‹ä»¶ï¼Œéœ€è¦æœç´¢å†å²èƒŒæ™¯",
                    "confidence": 0.82
                }
            
            # Priority 6: If interview is too short, continue
            if len(self.interview_dialogue) < 3:
                return {
                    "next_action": "continue_interview",
                    "reasoning": "è®¿è°ˆå†…å®¹å¤ªå°‘ï¼Œéœ€è¦æ›´å¤šä¿¡æ¯",
                    "confidence": 0.95
                }
            
            # Priority 7: If stuck in post_interview phase, move forward
            if self.current_phase == "post_interview":
                if not self.extracted_anchors:
                    return {
                        "next_action": "extract_events",
                        "reasoning": "è®¿è°ˆå·²ç»“æŸï¼Œå¼€å§‹æå–äº‹ä»¶",
                        "confidence": 0.8
                    }
                elif not self.biography:
                    return {
                        "next_action": "write_biography",
                        "reasoning": "ä¿¡æ¯å·²æ”¶é›†ï¼Œå¼€å§‹åˆ›ä½œ",
                        "confidence": 0.78
                    }
            
            # Default: continue interview if unsure
            return {
                "next_action": "continue_interview",
                "reasoning": "ä¸ç¡®å®šä¸‹ä¸€æ­¥ï¼Œç»§ç»­è®¿è°ˆæ”¶é›†æ›´å¤šä¿¡æ¯",
                "confidence": 0.6
            }
    
    async def conduct_interview_round(self) -> tuple[str, str]:
        """Conduct one round of interview."""
        model_client = model_manager.create_client()
        
        if len(self.interview_dialogue) == 0:
            # First question
            question = """ä½ å¥½ï¼æˆ‘æ˜¯ä¸“ä¸šçš„äººç”Ÿæ•…äº‹è®¿è°ˆå¸ˆï¼Œå¾ˆé«˜å…´èƒ½å¤Ÿå€¾å¬æ‚¨çš„æ•…äº‹ã€‚

ä»Šå¤©çš„ç›®æ ‡æ˜¯ä¸€èµ·å›é¡¾æ‚¨çš„äººç”Ÿå†ç¨‹ï¼ŒæŒ–æ˜çè´µçš„è®°å¿†å’Œç»å†ï¼Œä¸ºåˆ›ä½œæ‚¨çš„ä¸ªäººè‡ªä¼ æ”¶é›†ç´ æã€‚

è¯·å…ˆç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±å§ï¼Œæ¯”å¦‚å§“åã€å¹´é¾„ï¼Œä»¥åŠç°åœ¨çš„ç”Ÿæ´»çŠ¶å†µã€‚æˆ‘ä»¬å¯ä»¥ä»ä»»ä½•æ‚¨æ„¿æ„åˆ†äº«çš„åœ°æ–¹å¼€å§‹ã€‚

è¯·æ”¾è½»æ¾ï¼Œå°±åƒå’Œè€æœ‹å‹èŠå¤©ä¸€æ ·ã€‚"""
            
            self.display_agent_action("Interview Agent", "å¼€åœºé—®é¢˜", question)
            
        else:
            # Generate next question
            prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„äººç”Ÿæ•…äº‹è®¿è°ˆå¸ˆï¼Œæ­£åœ¨è¿›è¡Œæ·±åº¦è®¿è°ˆã€‚

å¯¹è¯å†å²:
{self.conversation_history[-1500:]}

ç”¨æˆ·æœ€æ–°å›ç­”: {self.interview_dialogue[-1]['content'] if self.interview_dialogue else ''}

åŸºäºç”¨æˆ·å›ç­”ï¼Œç”Ÿæˆä¸‹ä¸€ä¸ªæœ‰é’ˆå¯¹æ€§çš„è®¿è°ˆé—®é¢˜ã€‚

è¦æ±‚:
1. æ ¹æ®ç”¨æˆ·å›ç­”æ·±åº¦è°ƒæ•´é—®é¢˜
2. æ•æ‰æƒ…æ„Ÿçº¿ç´¢å’Œå…³é”®è¯
3. è‡ªç„¶è¿‡æ¸¡ä¸åŒäººç”Ÿé˜¶æ®µ
4. æ¸©æš–ã€å…±æƒ…ã€å¯å‘æ€§

æ ¼å¼:
<thinking>
  <intent>æ„å›¾åˆ†æ</intent>
  <memory>è®°å¿†å…³è”</memory>
  <mental_state>å¿ƒç†çŠ¶æ€</mental_state>
</thinking>
<response>ä½ çš„é—®é¢˜</response>"""
            
            response = await model_client.create(
                messages=[UserMessage(content=prompt, source="user")]
            )
            
            full_response = response.content.strip()
            
            # Extract thinking and question
            thinking_content = None
            question = full_response
            
            # First check if there are XML tags
            if "<thinking>" in full_response and "<response>" in full_response:
                # Extract thinking
                thinking_match = re.search(r'<thinking>(.*?)</thinking>', full_response, re.DOTALL)
                if thinking_match:
                    thinking_content = thinking_match.group(1).strip()
                    self.display_thinking("Interview Agent", thinking_content)
                
                # Extract response
                response_match = re.search(r'<response>(.*?)</response>', full_response, re.DOTALL)
                if response_match:
                    question = response_match.group(1).strip()
                else:
                    # Fallback: remove thinking tags and use rest
                    question = re.sub(r'<thinking>.*?</thinking>', '', full_response, flags=re.DOTALL).strip()
                    question = re.sub(r'</?response>', '', question).strip()
            elif "<thinking>" in full_response:
                # Only thinking, no response tag - extract what's outside thinking
                thinking_match = re.search(r'<thinking>(.*?)</thinking>', full_response, re.DOTALL)
                if thinking_match:
                    thinking_content = thinking_match.group(1).strip()
                    self.display_thinking("Interview Agent", thinking_content)
                    # Remove thinking tags from question
                    question = re.sub(r'<thinking>.*?</thinking>', '', full_response, flags=re.DOTALL).strip()
            elif "<response>" in full_response:
                # Only response tag
                response_match = re.search(r'<response>(.*?)</response>', full_response, re.DOTALL)
                if response_match:
                    question = response_match.group(1).strip()
            
            # Final cleanup - remove any remaining XML tags
            question = re.sub(r'</?thinking>', '', question).strip()
            question = re.sub(r'</?response>', '', question).strip()
            question = re.sub(r'</?intent>', '', question).strip()
            question = re.sub(r'</?memory>', '', question).strip()
            question = re.sub(r'</?mental_state>', '', question).strip()
            
            # If question is still empty or too short, use original
            if not question or len(question) < 10:
                question = full_response
            
            self.display_agent_action("Interview Agent", f"è®¿è°ˆé—®é¢˜ (ç¬¬{len(self.interview_dialogue)//2 + 1}è½®)", question)
        
        # Get user response
        user_response = input("\nğŸ‘¤ You: ").strip()
        
        # Record dialogue
        self.interview_dialogue.append({"speaker": "Interviewer", "content": question})
        self.interview_dialogue.append({"speaker": "You", "content": user_response})
        
        # Update content and history
        self.interview_content += f"Interviewer: {question}\nYou: {user_response}\n\n"
        self.conversation_history += f"\nInterviewer: {question}\nYou: {user_response}"
        
        return question, user_response
    
    async def extract_events(self):
        """Extract event anchors."""
        self.display_phase("history", "æå–å†å²äº‹ä»¶é”šç‚¹")
        self.display_agent_action("History Analyzer", "å¼€å§‹æå–äº‹ä»¶é”šç‚¹")
        
        self.extracted_anchors = await event_extractor.extract_event_anchors(self.interview_content)
        
        if self.extracted_anchors:
            print(f"\nâœ… æå–åˆ°äº‹ä»¶é”šç‚¹:")
            if 'temporal_anchors' in self.extracted_anchors:
                print(f"   â° æ—¶é—´é”šç‚¹: {', '.join(self.extracted_anchors['temporal_anchors'][:5])}")
            if 'location_anchors' in self.extracted_anchors:
                print(f"   ğŸ“ åœ°ç‚¹é”šç‚¹: {', '.join(self.extracted_anchors['location_anchors'][:5])}")
    
    async def research_history(self):
        """Research historical context."""
        self.display_phase("history", "ç ”ç©¶å†å²èƒŒæ™¯")
        self.display_agent_action("History Researcher", "å¼€å§‹å†å²èƒŒæ™¯ç ”ç©¶")
        
        if self.extracted_anchors:
            self.historical_context = await contextualizer.research_historical_context_enhanced(
                self.extracted_anchors
            )
            
            search_results = self.historical_context.get('search_results', [])
            if search_results:
                print(f"\nâœ… å®Œæˆ {len(search_results)} æ¬¡æœç´¢")
                for search_result in search_results[:2]:
                    query = search_result.get('query', '')
                    results = search_result.get('results', [])
                    self.display_search_results(query, results)
    
    async def write_biography(self):
        """Write or update biography."""
        self.display_phase("writing", "åˆ›ä½œè‡ªä¼ ")
        self.display_agent_action("Biography Writer", "å¼€å§‹åˆ›ä½œè‡ªä¼ ")
        
        model_client = model_manager.create_client()
        
        prompt = f"""åŸºäºä»¥ä¸‹è®¿è°ˆå†…å®¹å’Œå†å²èƒŒæ™¯ï¼Œåˆ›ä½œä¸€ç¯‡2000-3000å­—çš„ä¸ªäººè‡ªä¼ ã€‚

ä½¿ç”¨è‹±é›„ä¹‹æ—…æ¡†æ¶:
- Protagonist: è®¤è¯†è‡ªå·±ä½œä¸ºè‹±é›„/ä¸»è§’
- Shift: å…³é”®è½¬å˜æˆ–æ–°ä½“éªŒ
- Quest: æ˜ç¡®çš„ç›®æ ‡å’Œä½¿å‘½
- Allies: æ¥è‡ªä»–äººå’Œå¯¼å¸ˆçš„æ”¯æŒ
- Challenge: é¢ä¸´çš„éšœç¢å’Œå›°éš¾
- Transformation: ä¸ªäººæˆé•¿å’Œå˜åŒ–
- Legacy: å¯¹ä»–äººçš„æŒä¹…å½±å“

è®¿è°ˆå†…å®¹:
{self.interview_content}

å†å²èƒŒæ™¯:
{self.historical_context}

è¦æ±‚:
1. ç¬¬ä¸€äººç§°è§†è§’
2. çœŸå®æ„Ÿäººçš„è¯­è¨€
3. èåˆä¸ªäººç»å†ä¸æ—¶ä»£èƒŒæ™¯
4. çªå‡ºæˆé•¿ã€åšéŸ§å’Œæ™ºæ…§
5. ä¸°å¯Œçš„æƒ…æ„Ÿè¡¨è¾¾
6. ä¼˜ç¾çš„æ–‡å­¦è¯­è¨€
7. ç»“æ„å®Œæ•´ï¼Œé€»è¾‘æ¸…æ™°

è¯·åˆ›ä½œé«˜è´¨é‡è‡ªä¼ :"""
        
        response = await model_client.create(
            messages=[UserMessage(content=prompt, source="user")]
        )
        
        self.biography = response.content.strip()
        self.biography_versions.append({
            "version": len(self.biography_versions) + 1,
            "content": self.biography,
            "timestamp": datetime.now().isoformat()
        })
        
        print(f"\nâœ… è‡ªä¼ åˆ›ä½œå®Œæˆ (ç‰ˆæœ¬{len(self.biography_versions)}), {len(self.biography)}å­—")
        print("\n" + "=" * 80)
        print("ğŸ“– è‡ªä¼ å†…å®¹:")
        print("=" * 80)
        if len(self.biography) > 800:
            print(self.biography[:800] + "...")
        else:
            print(self.biography)
        print("=" * 80)
    
    async def evaluate_quality(self):
        """Evaluate biography quality."""
        self.display_phase("quality", "è´¨é‡è¯„ä¼°")
        self.display_agent_action("Quality Evaluator", "å¼€å§‹è¯„ä¼°")
        
        self.quality_result = await quality_critic.evaluate_biography_quality(self.biography)
        
        score = self.quality_result.get("overall_score", 0)
        print(f"\nâœ… è´¨é‡è¯„åˆ†: {score}/10.0")
        
        if "dimension_scores" in self.quality_result:
            print("\nğŸ“Š ç»´åº¦å¾—åˆ†:")
            for dim, s in self.quality_result["dimension_scores"].items():
                print(f"   {dim}: {s}/10.0")
    
    async def refine_biography(self):
        """Refine biography based on evaluation."""
        self.display_phase("refine", "ä¼˜åŒ–è‡ªä¼ ")
        self.display_agent_action("Biography Writer", "æ ¹æ®è¯„ä¼°åé¦ˆä¼˜åŒ–")
        
        model_client = model_manager.create_client()
        
        feedback = self.quality_result.get("feedback", "")
        
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹è¯„ä¼°åé¦ˆä¼˜åŒ–è¿™ç¯‡è‡ªä¼ :

å½“å‰è‡ªä¼ :
{self.biography}

è´¨é‡è¯„åˆ†: {self.quality_result.get('overall_score', 0)}/10.0

è¯„ä¼°åé¦ˆ:
{feedback}

è¯·ä¼˜åŒ–å¹¶è¿”å›æ”¹è¿›ç‰ˆæœ¬:"""
        
        response = await model_client.create(
            messages=[UserMessage(content=prompt, source="user")]
        )
        
        self.biography = response.content.strip()
        self.biography_versions.append({
            "version": len(self.biography_versions) + 1,
            "content": self.biography,
            "timestamp": datetime.now().isoformat(),
            "refined": True
        })
        
        print(f"\nâœ… è‡ªä¼ å·²ä¼˜åŒ– (ç‰ˆæœ¬{len(self.biography_versions)})")
    
    async def save_results(self):
        """Save all results."""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        person_id = f"smart_interactive_{timestamp}"
        
        # Save interview
        interview_file = file_manager.save_interview(
            person_id=person_id,
            interview_content=self.interview_content,
            dialogue=self.interview_dialogue
        )
        
        # Save final biography
        biography_file = file_manager.save_biography(
            person_id=person_id,
            biography_content=self.biography,
            version="final"
        )
        
        # Save all versions
        versions_file = file_manager.results_dir / "biographies" / f"{person_id}_all_versions.json"
        versions_file.parent.mkdir(parents=True, exist_ok=True)
        import json
        with open(versions_file, 'w', encoding='utf-8') as f:
            json.dump(self.biography_versions, f, ensure_ascii=False, indent=2)
        
        # Save evaluation
        evaluation_file = file_manager.save_evaluation(
            person_id=person_id,
            quality_result=self.quality_result,
            hero_journey_result=self.hero_journey_result
        )
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜:")
        print(f"   - è®¿è°ˆ: {interview_file}")
        print(f"   - è‡ªä¼ : {biography_file}")
        print(f"   - æ‰€æœ‰ç‰ˆæœ¬: {versions_file}")
        print(f"   - è¯„ä¼°: {evaluation_file}")
    
    async def run(self):
        """Run smart interactive session with coordinator control."""
        try:
            self.display_header()
            
            print(f"\nğŸ¤– å½“å‰AIæ¨¡å‹: {settings.default_model}")
            print(f"ğŸ§  ä½¿ç”¨æ™ºèƒ½åè°ƒè€…åŠ¨æ€ç®¡ç†æµç¨‹")
            
            ready = input("\nğŸš€ å‡†å¤‡å¼€å§‹å—ï¼Ÿ(y/n): ").lower()
            if ready != 'y':
                print("ğŸ‘‹ æœŸå¾…ä¸‹æ¬¡ä¸ºæ‚¨æœåŠ¡ï¼")
                return
            
            # Main loop controlled by coordinator
            max_iterations = 50  # Safety limit
            iteration = 0
            
            while iteration < max_iterations:
                iteration += 1
                
                # Coordinator decides next action
                self.display_agent_action("Coordinator", f"å†³ç­–ä¸‹ä¸€æ­¥è¡ŒåŠ¨ (è¿­ä»£{iteration})")
                decision = await self.coordinator_decide_next_action()
                self.display_coordinator_decision(decision)
                
                action = decision.get("next_action", "complete")
                reasoning = decision.get("reasoning", "æ— ")
                
                # Record action in history
                self.action_history.append((iteration, action, reasoning))
                
                # Execute action
                if action == "continue_interview":
                    self.display_phase("interview", "ç»§ç»­è®¿è°ˆ")
                    question, answer = await self.conduct_interview_round()
                    
                    if answer.lower() in ['quit', 'ç»“æŸ', 'end']:
                        print("\nâœ… ç”¨æˆ·è¯·æ±‚ç»“æŸè®¿è°ˆ")
                        continue
                
                elif action == "end_interview":
                    self.display_phase("interview", "è®¿è°ˆç»“æŸ")
                    print(f"âœ… è®¿è°ˆå®Œæˆï¼Œå…±{len(self.interview_dialogue)//2}è½®å¯¹è¯")
                    # Soft phase update - Coordinator can still make other decisions
                    if self.current_phase == "interview":
                        self.current_phase = "post_interview"
                
                elif action == "extract_events":
                    await self.extract_events()
                    # Don't force phase - let Coordinator decide
                
                elif action == "research_history":
                    await self.research_history()
                    # Don't force phase - let Coordinator decide
                
                elif action == "write_biography":
                    await self.write_biography()
                    # Don't force phase - let Coordinator decide
                
                elif action == "evaluate_quality":
                    await self.evaluate_quality()
                    # Don't force phase - let Coordinator decide
                
                elif action == "refine_biography":
                    await self.refine_biography()
                    # Re-evaluate after refinement
                    await self.evaluate_quality()
                
                elif action == "complete":
                    self.display_phase("completed", "æµç¨‹å®Œæˆï¼")
                    break
                
                else:
                    print(f"âš ï¸ æœªçŸ¥è¡ŒåŠ¨: {action}")
                    break
                
                # Small delay
                await asyncio.sleep(0.5)
            
            # Save results
            await self.save_results()
            
            # Final display
            print("\n" + "=" * 80)
            print("ğŸ“– æœ€ç»ˆè‡ªä¼ :")
            print("=" * 80)
            print(self.biography)
            print("=" * 80)
            
            print(f"\nğŸ‰ æ„Ÿè°¢ä½¿ç”¨SAGAç³»ç»Ÿï¼")
            print(f"ğŸ“Š å…±ç”Ÿæˆäº†{len(self.biography_versions)}ä¸ªç‰ˆæœ¬")
            
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


async def start_smart_interactive():
    """Start smart interactive mode."""
    session = SmartInteractiveSession()
    await session.run()


def main():
    """Main entry point."""
    try:
        asyncio.run(start_smart_interactive())
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ä¼šè¯ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()

