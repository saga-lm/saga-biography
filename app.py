#!/usr/bin/env python3
"""
Gradio Web UI for SAGA Biography Generation System.
Provides interactive interface for biography creation with real-time agent visualization.

Architecture:
- Uses interview_manager agent for structured interview methodology
- Uses biography_manager agent for biography writing and refinement
- Uses event_extractor and contextualizer tools for historical analysis
- Uses quality_critic and hero_evaluator tools for quality assessment
- Coordinator logic implemented inline for Gradio interactive workflow
"""

import asyncio
import sys
import json
from pathlib import Path
from datetime import datetime
import gradio as gr
from typing import Optional, List, Tuple
import warnings

# Suppress warnings
warnings.filterwarnings('ignore')

# Add src to Python path
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))

from session_manager import SessionManager
from autogen_core.models import UserMessage
from config.settings import settings
from src.models.client_manager import model_manager
from src.agents import interview_manager, biography_manager
from src.tools import event_extractor, contextualizer, quality_critic, hero_evaluator

# Initialize session manager
session_manager = SessionManager()


class GradioSAGASession:
    """SAGA session adapted for Gradio UI."""
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.session_data = session_manager.get_session(session_id)
    
    def log(self, level: str, message: str):
        """Add log entry."""
        session_manager.add_log(self.session_id, level, message)
        session_manager.save_session(self.session_id)
    
    def update(self, **kwargs):
        """Update session data."""
        session_manager.update_session(self.session_id, kwargs)
    
    def get_logs(self) -> str:
        """Get formatted logs."""
        return session_manager.get_logs(self.session_id)
    
    async def coordinator_decide_next_action(self) -> dict:
        """Coordinator decides what to do next."""
        self.log("INFO", "ğŸ§  Coordinatoræ­£åœ¨åˆ†æå¹¶å†³ç­–ä¸‹ä¸€æ­¥è¡ŒåŠ¨...")
        
        coordinator_client = model_manager.create_client()
        
        # Get recent action history
        action_history = self.session_data.get("action_history", [])
        recent_actions = action_history[-10:] if action_history else []
        action_summary = "\n".join([
            f"  è¿­ä»£{iter}: {action} - {reason}"
            for iter, action, reason in recent_actions
        ]) if recent_actions else "  å°šæœªæ‰§è¡Œä»»ä½•action"
        
        # Build context
        interview_dialogue = self.session_data.get("interview_dialogue", [])
        biography = self.session_data.get("biography", "")
        quality_result = self.session_data.get("quality_result", {})
        extracted_anchors = self.session_data.get("extracted_anchors")
        historical_context = self.session_data.get("historical_context", {})
        current_phase = self.session_data.get("current_phase", "starting")
        conversation_history = self.session_data.get("conversation_history", "")
        
        context = f"""å½“å‰çŠ¶æ€å¿«ç…§:
- å½“å‰é˜¶æ®µ: {current_phase}
- è®¿è°ˆè½®æ•°: {len(interview_dialogue) // 2}
- å·²æœ‰è‡ªä¼ : {'æ˜¯' if biography else 'å¦'} ({len(biography)} å­—)
- è´¨é‡è¯„ä¼°: {'æ˜¯' if quality_result else 'å¦'} ({quality_result.get('overall_score', 0):.1f}/10)
- äº‹ä»¶æå–: {'æ˜¯' if extracted_anchors else 'å¦'}
- å†å²ç ”ç©¶: {'æ˜¯' if historical_context else 'å¦'}

ğŸ“Š æœ€è¿‘æ‰§è¡Œçš„Actions:
{action_summary}

ğŸ“ æœ€è¿‘å¯¹è¯:
{conversation_history[-800:] if conversation_history else 'å°šæœªå¼€å§‹'}
"""
        
        prompt = f"""{context}

You are the intelligent Coordinator of the SAGA system, responsible for orchestrating multiple AI agents and tools to complete biography creation.

ğŸ¯ Your Role:
- Analyze current progress and decide the optimal next action
- Ensure logical workflow progression
- Balance information collection with quality output
- Coordinate between Interview, History Research, Writing, and Evaluation agents

ğŸ“‹ Available Actions and When to Use Them:

1. **continue_interview** - Continue collecting user's life story
   - Use when: Interview rounds < 8, or answers are rich but coverage incomplete
   - Don't use when: User responses become repetitive or very brief

2. **end_interview** - Conclude the interview phase
   - Use when: Interview rounds >= 10 and sufficient content collected
   - Signals transition to biography creation phase

3. **extract_events** - Extract temporal and location anchors from interview
   - Use when: Interview has substantial content but events not yet extracted
   - Required before historical research

4. **research_history** - Research historical context for extracted events
   - Use when: Events extracted but historical context not yet researched
   - Enriches biography with era background

5. **write_biography** - Create the autobiography using collected materials
   - Use when: Interview complete (6+ rounds) and ideally after history research
   - Can proceed without history research if anchors are sparse

6. **evaluate_quality** - Assess biography quality with 8-dimension evaluation
   - Use when: Biography exists but not yet evaluated
   - Always evaluate before refinement

7. **refine_biography** - Improve biography based on evaluation feedback
   - Use when: Biography evaluated and score < 9.0
   - Consider quality score and specific feedback

8. **complete** - Finish the entire process
   - Use when: Biography exists, evaluated, and quality score >= 8.5
   - Or after refinement attempt

ğŸ§  Decision Strategy:
- Prioritize interview depth over speed (aim for 8-12 rounds)
- Always extract events if interview is substantial
- Historical research is valuable but optional (depends on anchor quality)
- Always evaluate before considering refinement
- One refinement attempt is usually sufficient

Return your decision in JSON format:
{{
  "next_action": "action_name",
  "reasoning": "detailed reasoning for this decision based on current state",
  "confidence": 0.0-1.0
}}"""
        
        try:
            response = await coordinator_client.create(
                messages=[UserMessage(content=prompt, source="user")]
            )
            
            response_text = response.content.strip()
            
            # Extract JSON
            import re
            json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                response_text = json_match.group(1)
            
            decision = json.loads(response_text)
            
            self.log("SUCCESS", f"âœ… Coordinatorå†³ç­–: {decision.get('next_action')} (ç½®ä¿¡åº¦: {decision.get('confidence', 0):.2f})")
            self.log("INFO", f"   å†³ç­–ç†ç”±: {decision.get('reasoning', 'N/A')}")
            
            return decision
            
        except Exception as e:
            self.log("WARNING", f"âš ï¸ Coordinatorå†³ç­–å¤±è´¥ï¼Œä½¿ç”¨fallbacké€»è¾‘: {e}")
            
            # Fallback logic
            if biography and not quality_result:
                return {"next_action": "evaluate_quality", "reasoning": "æœ‰è‡ªä¼ ä½†æœªè¯„ä¼°", "confidence": 0.9}
            elif len(interview_dialogue) >= 6 and not biography:
                return {"next_action": "write_biography", "reasoning": "è®¿è°ˆå……è¶³ï¼Œå¯ä»¥åˆ›ä½œ", "confidence": 0.85}
            elif len(interview_dialogue) < 3:
                return {"next_action": "continue_interview", "reasoning": "è®¿è°ˆå†…å®¹å¤ªå°‘", "confidence": 0.95}
            else:
                return {"next_action": "continue_interview", "reasoning": "ç»§ç»­æ”¶é›†ä¿¡æ¯", "confidence": 0.7}
    
    async def conduct_interview_round(self, user_response: Optional[str] = None) -> Tuple[str, Optional[str]]:
        """Conduct one round of interview using interview agent's methodology."""
        if not user_response:
            return "", None
        
        model_client = model_manager.create_client()
        interview_dialogue = self.session_data.get("interview_dialogue", [])
        conversation_history = self.session_data.get("conversation_history", "")
        
        # Record user's previous answer first
        interview_dialogue.append({"speaker": "You", "content": user_response})
        conversation_history += f"\nYou: {user_response}"
        
        self.update(
            interview_dialogue=interview_dialogue,
            conversation_history=conversation_history,
            interview_content=self.session_data.get("interview_content", "") + f"You: {user_response}\n\n"
        )
        
        self.log("INFO", f"ğŸ‘¤ User response ({len(user_response)} chars)")
        
        # Calculate interview round to guide questioning strategy
        interview_round = len(interview_dialogue) // 2
        person_name = self.session_data.get("person_name", "User")
        
        # Stage-based interview strategy (from interview_agent)
        stage_guide = ""
        if interview_round <= 5:
            stage_guide = "Focus on: childhood, family background, early memories"
        elif interview_round <= 10:
            stage_guide = "Focus on: education, work experiences, career development"
        elif interview_round <= 15:
            stage_guide = "Focus on: relationships, marriage, family life"
        else:
            stage_guide = "Focus on: challenges, achievements, life reflections, wisdom"
        
        # Generate next question with interview agent's structured thinking
        prompt = f"""You are a senior life story interview expert conducting in-depth dialogue with {person_name}.

ğŸ¯ Interview goal: Collect complete life story including childhood, education, work, marriage, challenges and achievements.

Interview round: {interview_round}
Current stage strategy: {stage_guide}

Conversation history:
{conversation_history[-1500:]}

User's latest answer: "{user_response}"

ğŸ§  Thinking process (strictly follow):
<thinking>
  <intent>What information to collect this round, what to explore based on user's answer</intent>
  <memory>Key content user has shared, connections with previous dialogue</memory>
  <mental_state>User's current emotion and openness, unexpressed thoughts</mental_state>
</thinking>

Then generate ONE natural, warm, targeted follow-up question.

ğŸ¨ Interview strategy:
1. If user answers in detail â†’ dig deeper into emotions and details
2. If user answers briefly â†’ use more specific guiding questions  
3. Naturally transition between life stages
4. Focus on keywords and emotional clues in user's answer
5. Don't repeat previously asked questions
6. Build trust through warm, sincere tone

âš ï¸ Important: 
- Your response MUST include <thinking> tags with intent, memory, mental_state
- Then ask ONE clear question
- No multiple questions, no repeated questions
- Natural conversation style, not mechanical

Format:
<thinking>
  <intent>...</intent>
  <memory>...</memory>
  <mental_state>...</mental_state>
</thinking>

[Your single interview question]"""
        
        self.log("INFO", "ğŸ¤ Interview Agent generating next question...")
        
        response = await model_client.create(
            messages=[UserMessage(content=prompt, source="user")]
        )
        
        agent_response = response.content.strip()
        
        # Extract thinking and question (same parsing logic from interview_agent)
        thinking_content = None
        question = agent_response
        
        import re
        # Parse thinking tags
        thinking_match = re.search(r'<thinking>(.*?)</thinking>', agent_response, re.DOTALL)
        if thinking_match:
            thinking_content = thinking_match.group(1).strip()
            
            # Parse thinking components
            intent_match = re.search(r'<intent>(.*?)</intent>', thinking_content, re.DOTALL)
            memory_match = re.search(r'<memory>(.*?)</memory>', thinking_content, re.DOTALL)
            mental_match = re.search(r'<mental_state>(.*?)</mental_state>', thinking_content, re.DOTALL)
            
            thinking_parts = []
            if intent_match:
                thinking_parts.append(f"Intent: {intent_match.group(1).strip()}")
            if memory_match:
                thinking_parts.append(f"Memory: {memory_match.group(1).strip()}")
            if mental_match:
                thinking_parts.append(f"Mental: {mental_match.group(1).strip()}")
            
            if thinking_parts:
                self.log("INFO", f"ğŸ’­ {' | '.join(thinking_parts[:80])}")
            
            # Remove thinking from question
            question = re.sub(r'<thinking>.*?</thinking>', '', agent_response, flags=re.DOTALL).strip()
        
        # Remove any remaining XML tags
        question = re.sub(r'</?thinking>|</?intent>|</?memory>|</?mental_state>|</?response>', '', question).strip()
        
        # Fallback if extraction failed
        if not question or len(question) < 10:
            question = agent_response
        
        # Record question
        interview_dialogue.append({"speaker": "Interviewer", "content": question})
        conversation_history += f"\nInterviewer: {question}"
        
        self.update(
            interview_dialogue=interview_dialogue,
            conversation_history=conversation_history,
            interview_content=self.session_data.get("interview_content", "") + f"Interviewer: {question}\n\n"
        )
        
        self.log("SUCCESS", f"âœ… Interview Agent sent question #{len(interview_dialogue)//2}")
        
        return question, None
    
    async def extract_events(self):
        """Extract event anchors."""
        self.log("INFO", "ğŸ“š History Analyzeræ­£åœ¨æå–äº‹ä»¶é”šç‚¹...")
        self.update(current_phase="history_analysis")
        
        interview_content = self.session_data.get("interview_content", "")
        extracted_anchors = await event_extractor.extract_event_anchors(interview_content)
        
        self.update(extracted_anchors=extracted_anchors)
        
        if extracted_anchors:
            temporal = extracted_anchors.get('temporal_anchors', [])
            location = extracted_anchors.get('location_anchors', [])
            self.log("SUCCESS", f"âœ… æå–åˆ° {len(temporal)} ä¸ªæ—¶é—´é”šç‚¹ï¼Œ{len(location)} ä¸ªåœ°ç‚¹é”šç‚¹")
        else:
            self.log("WARNING", "âš ï¸ æœªæå–åˆ°æ˜æ˜¾çš„å†å²äº‹ä»¶é”šç‚¹")
    
    async def research_history(self):
        """Research historical context."""
        self.log("INFO", "ğŸ“š History Researcheræ­£åœ¨æœç´¢å†å²èƒŒæ™¯...")
        self.update(current_phase="historical_research")
        
        extracted_anchors = self.session_data.get("extracted_anchors")
        
        if extracted_anchors:
            historical_context = await contextualizer.research_historical_context_enhanced(
                extracted_anchors
            )
            
            self.update(historical_context=historical_context)
            
            search_results = historical_context.get('search_results', [])
            if search_results:
                self.log("SUCCESS", f"âœ… å®Œæˆ {len(search_results)} æ¬¡å†å²èƒŒæ™¯æœç´¢")
                for search_result in search_results[:2]:
                    query = search_result.get('query', '')
                    self.log("INFO", f"   ğŸ” æœç´¢: {query}")
            else:
                self.log("WARNING", "âš ï¸ å†å²èƒŒæ™¯æœç´¢æœªè¿”å›ç»“æœ")
        else:
            self.log("WARNING", "âš ï¸ æ²¡æœ‰äº‹ä»¶é”šç‚¹å¯ä¾›ç ”ç©¶")
    
    async def write_biography(self):
        """Write or update biography using biography_manager agent."""
        self.log("INFO", "âœï¸ Biography Writer Agentæ­£åœ¨åˆ›ä½œè‡ªä¼ ...")
        self.update(current_phase="writing")
        
        interview_content = self.session_data.get("interview_content", "")
        historical_context = self.session_data.get("historical_context", {})
        
        # Build minimal person_data for biography_manager
        person_data = {
            "person_info": {
                "name": self.session_data.get("person_name", "User"),
                "basic_data": self.session_data.get("basic_data", {}),
                "personal_background": self.session_data.get("personal_background", {})
            }
        }
        
        # Use biography_manager agent to generate biography
        biography = await biography_manager.generate_biography(
            interview_content=interview_content,
            historical_context=historical_context,
            person_data=person_data
        )
        
        biography_versions = self.session_data.get("biography_versions", [])
        biography_versions.append({
            "version": len(biography_versions) + 1,
            "content": biography,
            "timestamp": datetime.now().isoformat()
        })
        
        self.update(
            biography=biography,
            biography_versions=biography_versions
        )
        
        self.log("SUCCESS", f"âœ… Biography created by agent (v{len(biography_versions)}, {len(biography)} chars)")
    
    async def evaluate_quality(self):
        """Evaluate biography quality."""
        self.log("INFO", "ğŸ” Quality Evaluatoræ­£åœ¨è¯„ä¼°è´¨é‡...")
        self.update(current_phase="quality_assessment")
        
        biography = self.session_data.get("biography", "")
        
        if not biography:
            self.log("ERROR", "âŒ æ²¡æœ‰è‡ªä¼ å†…å®¹å¯ä¾›è¯„ä¼°")
            return
        
        quality_result = await quality_critic.evaluate_biography_quality(biography)
        self.update(quality_result=quality_result)
        
        score = quality_result.get("overall_score", 0)
        quality_level = quality_result.get("quality_level", "unknown")
        
        self.log("SUCCESS", f"âœ… è´¨é‡è¯„åˆ†: {score:.1f}/10.0 ({quality_level})")
        
        if "dimension_scores" in quality_result:
            dims = quality_result["dimension_scores"]
            self.log("INFO", f"   ğŸ“Š ç»´åº¦å¾—åˆ†: å†…å®¹{dims.get('content_completeness', 0):.1f} | "
                     f"æƒ…æ„Ÿ{dims.get('emotional_depth', 0):.1f} | "
                     f"æ–‡å­¦{dims.get('literary_quality', 0):.1f} | "
                     f"å†å²{dims.get('historical_integration', 0):.1f}")
    
    async def refine_biography(self):
        """Refine biography using biography_manager agent's improvement methods."""
        self.log("INFO", "ğŸ”„ Biography Writer Agentæ­£åœ¨ä¼˜åŒ–è‡ªä¼ ...")
        self.update(current_phase="refinement")
        
        biography = self.session_data.get("biography", "")
        quality_result = self.session_data.get("quality_result", {})
        historical_context = self.session_data.get("historical_context", {})
        person_name = self.session_data.get("person_name", "User")
        
        overall_score = quality_result.get("overall_score", 0.0)
        dimension_scores = quality_result.get("dimension_scores", {})
        
        # Decide refinement strategy based on quality score and dimension analysis
        if overall_score < 7.5:
            # Low score: use comprehensive improvement
            self.log("INFO", "ğŸ“Š Score below 7.5, applying comprehensive improvement...")
            biography = await biography_manager.improve_biography(
                biography=biography,
                quality_result=quality_result,
                historical_context=historical_context,
                person_name=person_name
            )
        else:
            # Medium score: focus on Hero's Journey structure enhancement
            self.log("INFO", "ğŸ“Š Score 7.5+, enhancing Hero's Journey structure...")
            biography = await biography_manager.enhance_hero_journey_structure(
                biography=biography,
                quality_result=quality_result,
                person_name=person_name
            )
        
        biography_versions = self.session_data.get("biography_versions", [])
        biography_versions.append({
            "version": len(biography_versions) + 1,
            "content": biography,
            "timestamp": datetime.now().isoformat(),
            "refined": True,
            "refinement_strategy": "comprehensive" if overall_score < 7.5 else "hero_journey"
        })
        
        self.update(
            biography=biography,
            biography_versions=biography_versions
        )
        
        self.log("SUCCESS", f"âœ… Biography refined by agent (v{len(biography_versions)})")


# ============================================================================
# Gradio Interface Functions
# ============================================================================

def create_new_session():
    """Create new session with proper initialization."""
    session_id, session_data = session_manager.create_session()
    session_manager.add_log(session_id, "INFO", f"ğŸš€ System initialized, Session ID: {session_id}")
    session_manager.add_log(session_id, "INFO", f"ğŸ¤– AI Model: {settings.default_model}")
    
    # Initialize person info (will be updated when user introduces themselves)
    session_data['person_name'] = "User"
    session_data['basic_data'] = {}
    session_data['personal_background'] = {}
    
    # Generate opening question (aligned with interview_agent style)
    opening_question = """Hello! I'm a professional life story interviewer, honored to listen to your story.

Today's goal is to review your life journey together, uncover precious memories and experiences, and collect materials for creating your personal autobiography.

Please start by briefly introducing yourself - your name, age, and current life situation. We can begin wherever you're comfortable sharing.

Please relax, just like chatting with an old friend."""
    
    # Record opening question in session
    session_data['interview_dialogue'] = [{"speaker": "Interviewer", "content": opening_question}]
    session_data['conversation_history'] = f"Interviewer: {opening_question}"
    session_data['interview_content'] = f"Interviewer: {opening_question}\n\n"
    session_manager.update_session(session_id, session_data)
    session_manager.add_log(session_id, "INFO", "ğŸ¤ Interview Agent sent opening question")
    session_manager.save_session(session_id)
    
    logs = session_manager.get_logs(session_id)
    
    # Display opening question in chatbot
    chatbot_initial = [(None, opening_question)]
    
    return (
        session_id,  # session_id_display
        gr.update(visible=True),  # main_interface
        gr.update(visible=False),  # start_interface
        chatbot_initial,  # chatbot with opening question
        "",  # user_input
        {},  # coordinator_output
        "å½“å‰é˜¶æ®µ: starting\nè®¿è°ˆè½®æ•°: 0",  # agent_status
        "",  # biography_display
        logs,  # log_display
        []  # version_dropdown
    )


def resume_existing_session(resume_session_id):
    """Resume existing session."""
    if not resume_session_id:
        return (
            gr.update(),
            gr.update(value="âš ï¸ è¯·è¾“å…¥ä¼šè¯ID"),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update()
        )
    
    session_data = session_manager.get_session(resume_session_id)
    
    if not session_data:
        return (
            gr.update(),
            gr.update(value=f"âŒ ä¼šè¯IDä¸å­˜åœ¨: {resume_session_id}"),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update()
        )
    
    # Reconstruct chatbot history
    dialogue = session_data.get("interview_dialogue", [])
    chatbot_history = []
    
    # å¯¹è¯æ ¼å¼ï¼š[(user_msg, bot_msg), (user_msg, bot_msg), ...]
    # dialogueä¸­æ˜¯äº¤æ›¿çš„ Interviewer å’Œ You
    i = 0
    while i < len(dialogue):
        if i == 0 and dialogue[0]["speaker"] == "Interviewer":
            # ç¬¬ä¸€æ¡æ˜¯å¼€åœºé—®é¢˜ï¼Œæ²¡æœ‰ç”¨æˆ·è¾“å…¥
            chatbot_history.append((None, dialogue[0]["content"]))
            i += 1
        elif i + 1 < len(dialogue):
            # æ­£å¸¸çš„ä¸€é—®ä¸€ç­”
            if dialogue[i]["speaker"] == "You" and dialogue[i + 1]["speaker"] == "Interviewer":
                chatbot_history.append((dialogue[i]["content"], dialogue[i + 1]["content"]))
                i += 2
            else:
                i += 1
        else:
            # æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯è¿˜æ²¡æœ‰å›å¤
            if dialogue[i]["speaker"] == "You":
                chatbot_history.append((dialogue[i]["content"], None))
            i += 1
    
    # Get biography
    biography = session_data.get("biography", "*è‡ªä¼ å°šæœªç”Ÿæˆ*")
    
    # Get versions
    versions = session_data.get("biography_versions", [])
    version_choices = [f"ç‰ˆæœ¬ {v['version']} - {v['timestamp'][:19]}" for v in versions]
    
    # Get logs
    logs = session_manager.get_logs(resume_session_id)
    
    session_manager.add_log(resume_session_id, "INFO", f"ğŸ”„ ä¼šè¯å·²æ¢å¤: {resume_session_id}")
    session_manager.save_session(resume_session_id)
    logs = session_manager.get_logs(resume_session_id)
    
    return (
        resume_session_id,  # session_id_display
        gr.update(visible=True),  # main_interface
        gr.update(visible=False),  # start_interface
        chatbot_history,  # chatbot
        biography,  # biography_display
        version_choices,  # version_dropdown
        logs,  # log_display
        "âœ… ä¼šè¯å·²æˆåŠŸæ¢å¤ï¼"  # status_message
    )


async def handle_send_message(user_input, session_id, chatbot_history):
    """Handle user sending a message."""
    if not user_input or not session_id:
        return (chatbot_history, "", gr.update(), gr.update(), gr.update(), 
                gr.update(), gr.update(), gr.update())
    
    session = GradioSAGASession(session_id)
    
    # Add user message to chatbot
    chatbot_history.append((user_input, None))
    
    # Conduct interview round
    question, _ = await session.conduct_interview_round(user_response=user_input)
    
    # Add interviewer response
    if chatbot_history:
        chatbot_history[-1] = (user_input, question)
    
    # Get coordinator decision
    decision = await session.coordinator_decide_next_action()
    
    # Record action
    action_history = session.session_data.get("action_history", [])
    action_history.append((len(action_history) + 1, decision.get("next_action"), decision.get("reasoning")))
    session.update(action_history=action_history)
    
    logs = session.get_logs()
    
    # Get Agentå·¥ä½œæˆæœ
    extracted_anchors = session.session_data.get("extracted_anchors")
    historical_context = session.session_data.get("historical_context", {})
    quality_result = session.session_data.get("quality_result", {})
    
    # æ ¼å¼åŒ–å†å²ç ”ç©¶æ˜¾ç¤º
    if historical_context and historical_context.get('search_results'):
        history_md = "## å†å²èƒŒæ™¯ç ”ç©¶\n\n"
        for idx, result in enumerate(historical_context.get('search_results', [])[:3], 1):
            query = result.get('query', 'æœªçŸ¥æŸ¥è¯¢')
            summary = result.get('summary', 'æ— æ‘˜è¦')
            history_md += f"### ğŸ” æŸ¥è¯¢ {idx}: {query}\n\n{summary}\n\n---\n\n"
    else:
        history_md = "*å°šæœªè¿›è¡Œå†å²ç ”ç©¶*"
    
    return (
        chatbot_history,
        "",  # Clear input
        decision,  # coordinator_output
        f"å½“å‰é˜¶æ®µ: {session.session_data.get('current_phase', 'interview')}\nè®¿è°ˆè½®æ•°: {len(session.session_data.get('interview_dialogue', [])) // 2}",
        logs,
        extracted_anchors,  # extracted_events_display
        history_md,  # historical_research_display
        quality_result  # quality_evaluation_display
    )


async def handle_coordinator_action(action_name, session_id):
    """Execute coordinator action manually."""
    if not session_id:
        return "âŒ æ²¡æœ‰æ´»åŠ¨ä¼šè¯", gr.update()
    
    session = GradioSAGASession(session_id)
    
    try:
        if action_name == "extract_events":
            await session.extract_events()
        elif action_name == "research_history":
            await session.research_history()
        elif action_name == "write_biography":
            await session.write_biography()
        elif action_name == "evaluate_quality":
            await session.evaluate_quality()
        elif action_name == "refine_biography":
            await session.refine_biography()
        elif action_name == "write_and_evaluate":
            # åˆ›ä½œä¼ è®°å¹¶è‡ªåŠ¨è¯„ä¼°
            await session.write_biography()
            await session.evaluate_quality()
        else:
            return f"âŒ æœªçŸ¥æ“ä½œ: {action_name}", gr.update()
        
        logs = session.get_logs()
        biography = session.session_data.get("biography", "*è‡ªä¼ å°šæœªç”Ÿæˆ*")
        
        return logs, biography
        
    except Exception as e:
        session.log("ERROR", f"âŒ æ‰§è¡Œæ“ä½œå¤±è´¥: {e}")
        logs = session.get_logs()
        return logs, gr.update()


def copy_to_clipboard(session_id):
    """Copy biography to clipboard."""
    session_data = session_manager.get_session(session_id)
    if not session_data:
        return "âŒ ä¼šè¯ä¸å­˜åœ¨"
    
    biography = session_data.get("biography", "")
    if not biography:
        return "âš ï¸ è¿˜æ²¡æœ‰è‡ªä¼ å†…å®¹"
    
    return biography  # Gradio will handle clipboard


def export_biography(session_id, format_type):
    """Export biography to file for browser download."""
    session_data = session_manager.get_session(session_id)
    if not session_data:
        return None
    
    biography = session_data.get("biography", "")
    if not biography:
        return None
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä½¿ç”¨ä¸´æ—¶ç›®å½•
    import tempfile
    temp_dir = Path(tempfile.gettempdir())
    
    if format_type == "TXT":
        filename = f"biography_{timestamp}.txt"
        filepath = temp_dir / filename
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(biography)
        return str(filepath)
    
    elif format_type == "JSON":
        filename = f"biography_{timestamp}.json"
        filepath = temp_dir / filename
        export_data = session_manager.export_session_data(session_id)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        return str(filepath)
    
    return None


def export_logs(session_id):
    """Export logs to file for browser download."""
    logs = session_manager.get_logs(session_id)
    if not logs:
        return gr.update(visible=False)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    import tempfile
    temp_dir = Path(tempfile.gettempdir())
    filename = f"saga_logs_{timestamp}.txt"
    filepath = temp_dir / filename
    
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write(logs)
    
    # è¿”å›æ–‡ä»¶è·¯å¾„å¹¶æ˜¾ç¤ºä¸‹è½½ç»„ä»¶
    return gr.update(value=filepath.absolute().__str__(), visible=True)


def export_session(session_id):
    """Export complete session data as JSON."""
    if not session_id:
        return gr.update(visible=False)
    
    export_data = session_manager.export_session_data(session_id)
    if not export_data:
        return gr.update(visible=False)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    import tempfile
    temp_dir = Path(tempfile.gettempdir())
    filename = f"saga_session_{timestamp}.json"
    filepath = temp_dir / filename
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(export_data, f, ensure_ascii=False, indent=2)
    
    # è¿”å›æ–‡ä»¶è·¯å¾„å¹¶æ˜¾ç¤ºä¸‹è½½ç»„ä»¶
    return gr.update(value=filepath.absolute().__str__(), visible=True)


def import_session(file_path):
    """Import session from JSON file."""
    if not file_path:
        return (
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            "âš ï¸ è¯·é€‰æ‹©æ–‡ä»¶"
        )
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            import_data = json.load(f)
        
        # åˆ›å»ºæ–°çš„ä¼šè¯ID
        session_id, session_data = session_manager.create_session()
        
        # ä»å¯¼å…¥æ•°æ®ä¸­æå–ä¿¡æ¯å¹¶æ›´æ–°ä¼šè¯
        updates = {}
        
        # å¤„ç†ä¸åŒçš„å¯¼å‡ºæ ¼å¼
        if "metadata" in import_data:
            # æ–°æ ¼å¼ï¼ˆä½¿ç”¨export_session_dataå¯¼å‡ºçš„ï¼‰
            if "interview" in import_data:
                updates["interview_dialogue"] = import_data["interview"].get("dialogue", [])
                updates["interview_content"] = import_data["interview"].get("content", "")
            
            if "biography" in import_data:
                updates["biography"] = import_data["biography"].get("final_version", "")
                updates["biography_versions"] = import_data["biography"].get("all_versions", [])
            
            if "evaluation" in import_data:
                updates["quality_result"] = import_data["evaluation"].get("quality", {})
                updates["hero_journey_result"] = import_data["evaluation"].get("hero_journey", {})
            
            if "research" in import_data:
                updates["extracted_anchors"] = import_data["research"].get("extracted_anchors")
                updates["historical_context"] = import_data["research"].get("historical_context", {})
            
            if "workflow" in import_data:
                updates["current_phase"] = import_data["workflow"].get("current_phase", "starting")
                updates["action_history"] = import_data["workflow"].get("action_history", [])
        else:
            # æ—§æ ¼å¼ï¼ˆç›´æ¥çš„sessionæ•°æ®ï¼‰
            updates = import_data
        
        # æ›´æ–°ä¼šè¯
        session_manager.update_session(session_id, updates)
        session_data = session_manager.get_session(session_id)
        
        # é‡å»ºå¯¹è¯å†å²
        dialogue = session_data.get("interview_dialogue", [])
        chatbot_history = []
        
        i = 0
        while i < len(dialogue):
            if i == 0 and dialogue[0]["speaker"] == "Interviewer":
                chatbot_history.append((None, dialogue[0]["content"]))
                i += 1
            elif i + 1 < len(dialogue):
                if dialogue[i]["speaker"] == "You" and dialogue[i + 1]["speaker"] == "Interviewer":
                    chatbot_history.append((dialogue[i]["content"], dialogue[i + 1]["content"]))
                    i += 2
                else:
                    i += 1
            else:
                if dialogue[i]["speaker"] == "You":
                    chatbot_history.append((dialogue[i]["content"], None))
                i += 1
        
        # è·å–ä¼ è®°
        biography = session_data.get("biography", "*è‡ªä¼ å°šæœªç”Ÿæˆ*")
        
        # è·å–ç‰ˆæœ¬
        versions = session_data.get("biography_versions", [])
        version_choices = [f"ç‰ˆæœ¬ {v['version']} - {v['timestamp'][:19]}" for v in versions]
        
        # æ·»åŠ æ—¥å¿—
        session_manager.add_log(session_id, "INFO", f"ğŸ“¥ å·²ä»JSONæ–‡ä»¶å¯¼å…¥ä¼šè¯ï¼ˆåŒ…å«{len(dialogue)}æ¡å¯¹è¯ï¼‰")
        session_manager.save_session(session_id)
        logs = session_manager.get_logs(session_id)
        
        # Get Agentå·¥ä½œæˆæœ
        extracted_anchors = session_data.get("extracted_anchors")
        historical_context = session_data.get("historical_context", {})
        quality_result = session_data.get("quality_result", {})
        
        # æ ¼å¼åŒ–å†å²ç ”ç©¶æ˜¾ç¤º
        if historical_context and historical_context.get('search_results'):
            history_md = "## å†å²èƒŒæ™¯ç ”ç©¶\n\n"
            for idx, result in enumerate(historical_context.get('search_results', [])[:3], 1):
                query = result.get('query', 'æœªçŸ¥æŸ¥è¯¢')
                summary = result.get('summary', 'æ— æ‘˜è¦')
                history_md += f"### ğŸ” æŸ¥è¯¢ {idx}: {query}\n\n{summary}\n\n---\n\n"
        else:
            history_md = "*å°šæœªè¿›è¡Œå†å²ç ”ç©¶*"
        
        return (
            session_id,  # session_id_display
            chatbot_history,  # chatbot
            biography,  # biography_display
            version_choices,  # version_dropdown
            logs,  # log_display
            f"å½“å‰é˜¶æ®µ: {session_data.get('current_phase', 'starting')}\nè®¿è°ˆè½®æ•°: {len(dialogue) // 2}",  # agent_status
            {},  # coordinator_output
            "âœ… ä¼šè¯å·²æˆåŠŸå¯¼å…¥ï¼",  # status_message
            extracted_anchors,  # extracted_events_display
            history_md,  # historical_research_display
            quality_result  # quality_evaluation_display
        )
        
    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"Import error: {error_detail}")
        return (
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            f"âŒ å¯¼å…¥å¤±è´¥: {str(e)}",
            gr.update(),
            gr.update(),
            gr.update()
        )


# ============================================================================
# Gradio UI Layout
# ============================================================================

def create_gradio_interface():
    """Create Gradio interface."""
    
    with gr.Blocks(
        theme=gr.themes.Soft(primary_hue="blue", secondary_hue="orange"),
        title="SAGAä¼ è®°ç”Ÿæˆç³»ç»Ÿ",
        css="""
        /* å…¨å±€æ ·å¼ä¼˜åŒ– */
        .gradio-container {
            font-family: 'Segoe UI', 'Microsoft YaHei', sans-serif !important;
        }
        
        /* åœ†è§’ç¾åŒ– */
        .gr-button {
            border-radius: 12px !important;
            transition: all 0.3s ease !important;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1) !important;
        }
        
        .gr-button:hover {
            transform: translateY(-2px) !important;
            box-shadow: 0 4px 12px rgba(0,0,0,0.15) !important;
        }
        
        .gr-box, .gr-input, .gr-text-input, textarea {
            border-radius: 16px !important;
            border: 1px solid #e0e0e0 !important;
            box-shadow: 0 2px 6px rgba(0,0,0,0.05) !important;
        }
        
        .gr-panel {
            border-radius: 20px !important;
            box-shadow: 0 4px 16px rgba(0,0,0,0.08) !important;
        }
        
        .gr-accordion {
            border-radius: 16px !important;
            overflow: hidden !important;
        }
        
        /* Chatbotç¾åŒ– - è“ç»¿æµ…è‰²é…è‰² */
        .message-wrap {
            border-radius: 18px !important;
            padding: 12px !important;
            margin: 8px 0 !important;
        }
        
        .message.user {
            background: linear-gradient(135deg, #a8e6cf 0%, #81c784 100%) !important;
            border-radius: 18px 18px 4px 18px !important;
            color: #2e5d4e !important;
        }
        
        .message.bot {
            background: linear-gradient(135deg, #b3d9ff 0%, #81b3ff 100%) !important;
            border-radius: 18px 18px 18px 4px !important;
            color: #1a4d7a !important;
        }
        
        /* AgentçŠ¶æ€æ ‡ç­¾ç¾åŒ– */
        .agent-coordinator { 
            border-left: 5px solid #FF8C00 !important;
            border-radius: 0 12px 12px 0 !important;
            padding-left: 16px !important;
        }
        .agent-interview { 
            border-left: 5px solid #4169E1 !important;
            border-radius: 0 12px 12px 0 !important;
            padding-left: 16px !important;
        }
        .agent-history { 
            border-left: 5px solid #9370DB !important;
            border-radius: 0 12px 12px 0 !important;
            padding-left: 16px !important;
        }
        .agent-writer { 
            border-left: 5px solid #32CD32 !important;
            border-radius: 0 12px 12px 0 !important;
            padding-left: 16px !important;
        }
        .agent-evaluator { 
            border-left: 5px solid #DC143C !important;
            border-radius: 0 12px 12px 0 !important;
            padding-left: 16px !important;
        }
        
        /* è¾“å…¥æ¡†å¢å¼º */
        textarea:focus, input:focus {
            outline: none !important;
            border-color: #667eea !important;
            box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1) !important;
        }
        
        /* å¡ç‰‡å®¹å™¨ */
        .gr-group {
            border-radius: 20px !important;
            box-shadow: 0 4px 20px rgba(0,0,0,0.08) !important;
            border: none !important;
        }
        
        /* ä¸»è¦æŒ‰é’®å¼ºåŒ– */
        .gr-button-primary {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
            border: none !important;
            font-weight: 600 !important;
        }
        
        .gr-button-primary:hover {
            background: linear-gradient(135deg, #764ba2 0%, #667eea 100%) !important;
        }
        
        /* æ»šåŠ¨æ¡ç¾åŒ– */
        ::-webkit-scrollbar {
            width: 10px;
            height: 10px;
        }
        
        ::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 10px;
        }
        
        ::-webkit-scrollbar-thumb {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 10px;
        }
        
        ::-webkit-scrollbar-thumb:hover {
            background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
        }
        
        /* æ ‡é¢˜ç¾åŒ– - å¢å¼ºç‰ˆ */
        h1 {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: 700 !important;
            font-size: 2.2em !important;
            margin-bottom: 0.5em !important;
        }
        
        h2 {
            color: #4a5568 !important;
            font-weight: 600 !important;
            font-size: 1.5em !important;
            margin-top: 1.5em !important;
            margin-bottom: 0.8em !important;
            padding-bottom: 0.5em !important;
            border-bottom: 2px solid #e2e8f0 !important;
        }
        
        h3 {
            background: linear-gradient(135deg, #4299e1 0%, #667eea 100%);
            color: white !important;
            font-weight: 600 !important;
            font-size: 1.1em !important;
            padding: 10px 16px !important;
            border-radius: 12px !important;
            margin-top: 1.2em !important;
            margin-bottom: 0.8em !important;
            box-shadow: 0 2px 8px rgba(66, 153, 225, 0.3) !important;
            display: inline-block !important;
            width: 100% !important;
        }
        
        /* è®©emojiåœ¨æ ‡é¢˜ä¸­æ›´å¥½çœ‹ */
        h3::before {
            margin-right: 8px;
        }
        
        /* ä¼šè¯IDæ ·å¼ä¼˜åŒ– */
        .session-id-label {
            margin-bottom: 8px !important;
        }
        
        .session-id-label p {
            margin: 0 !important;
            font-size: 0.85em !important;
            color: #718096 !important;
            font-weight: 500 !important;
        }
        
        .session-id-text input {
            font-family: 'Monaco', 'Menlo', 'Courier New', monospace !important;
            font-size: 0.85em !important;
            color: #2d3748 !important;
            background: #f7fafc !important;
            border: 1px solid #cbd5e0 !important;
            border-radius: 8px !important;
            padding: 10px 12px !important;
            height: 42px !important;
            line-height: 1.5 !important;
        }
        
        .session-id-text input:hover {
            border-color: #a0aec0 !important;
        }
        
        /* ç»Ÿä¸€æŒ‰é’®é«˜åº¦ */
        .gr-button-sm {
            height: 42px !important;
            min-height: 42px !important;
        }
        
        /* å¤§æŒ‰é’®æ ·å¼ä¼˜åŒ– */
        .gr-button-lg {
            font-size: 1.05em !important;
            font-weight: 600 !important;
            padding: 14px 28px !important;
            border-radius: 12px !important;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1) !important;
            transition: all 0.3s ease !important;
        }
        
        .gr-button-lg:hover {
            transform: translateY(-2px) !important;
            box-shadow: 0 6px 16px rgba(0, 0, 0, 0.15) !important;
        }
        """
    ) as demo:
        
        # Header
        gr.Markdown("""
        # ğŸ­ SAGAä¼ è®°ç”Ÿæˆç³»ç»Ÿ
        
        æ™ºèƒ½å¤šAgentåä½œï¼Œä¸ºæ‚¨åˆ›ä½œä¸“å±ä¼ è®°
        """)
        
        # Start Interface
        with gr.Group(visible=True) as start_interface:
            gr.Markdown("""
            ## æ¬¢è¿ä½¿ç”¨SAGAç³»ç»Ÿï¼
            
            æ‚¨å¯ä»¥ï¼š
            - ğŸ†• åˆ›å»ºæ–°ä¼šè¯ï¼Œå¼€å§‹ä¼ è®°åˆ›ä½œ
            - ğŸ”„ æ¢å¤å†å²ä¼šè¯ï¼Œç»§ç»­ä¹‹å‰çš„åˆ›ä½œ
            - ğŸ“¥ å¯¼å…¥JSONæ–‡ä»¶ï¼Œæ–­ç‚¹ç»­ä¼ 
            """)
            
            with gr.Row(equal_height=True):
                with gr.Column():
                    gr.Markdown("### ğŸ†• å¼€å§‹æ–°ä¼šè¯")
                    start_btn = gr.Button("å¼€å§‹æ–°ä¼šè¯", variant="primary", size="lg")
                
                with gr.Column():
                    gr.Markdown("### ğŸ”„ æ¢å¤å†å²ä¼šè¯")
                    resume_input = gr.Textbox(
                        label="è¾“å…¥ä¼šè¯ID",
                        placeholder="ä¾‹å¦‚: user_20241114_123456_abc12345",
                        show_label=False
                    )
                    resume_btn = gr.Button("æ¢å¤ä¼šè¯", size="lg")
                
                with gr.Column():
                    gr.Markdown("### ğŸ“¥ å¯¼å…¥ä¼šè¯JSON")
                    import_start_file = gr.UploadButton(
                        "é€‰æ‹©JSONæ–‡ä»¶",
                        file_types=[".json"],
                        file_count="single",
                        size="lg"
                    )
        
        # Main Interface
        with gr.Group(visible=False) as main_interface:
            # Session ID Display å’Œ å¯¼å…¥/å¯¼å‡ºï¼ˆç´§å‡‘å¸ƒå±€ï¼‰
            gr.Markdown("**ğŸ“Œ å½“å‰ä¼šè¯ID**", elem_classes=["session-id-label"])
            with gr.Row():
                session_id_display = gr.Textbox(
                    value="",
                    interactive=False,
                    show_label=False,
                    container=False,
                    lines=1,
                    scale=6,
                    elem_classes=["session-id-text"]
                )
                import_session_btn = gr.UploadButton(
                    "ğŸ“¥ å¯¼å…¥",
                    file_types=[".json"],
                    file_count="single",
                    size="sm",
                    variant="secondary",
                    scale=1
                )
                export_session_btn = gr.Button(
                    "ğŸ’¾ å¯¼å‡º",
                    size="sm",
                    variant="secondary",
                    scale=1
                )
            
            # ä¸‹è½½æ–‡ä»¶ç»„ä»¶ï¼ˆåˆå§‹éšè—ï¼Œå¯¼å‡ºåæ˜¾ç¤ºï¼‰
            download_session_file = gr.File(label="ğŸ“¦ ç‚¹å‡»ä¸‹è½½å¯¼å‡ºæ–‡ä»¶", visible=False, height=60, interactive=False)
            
            # Main Layout
            with gr.Row():
                # Left Column: å¯¹è¯äº¤äº’ + ä¼ è®°å†…å®¹
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ’¬ å¯¹è¯äº¤äº’")
                    
                    chatbot = gr.Chatbot(
                        label="è®¿è°ˆå¯¹è¯",
                        height=400,
                        show_label=False
                    )
                    
                    with gr.Row():
                        user_input = gr.Textbox(
                            label="æ‚¨çš„å›ç­”",
                            placeholder="è¯·è¾“å…¥æ‚¨çš„å›ç­”ï¼ŒæŒ‰Enterå‘é€...",
                            lines=3,
                            scale=4
                        )
                        send_btn = gr.Button("ğŸ“¤ å‘é€", variant="primary", scale=1, size="lg")
                    
                    gr.Markdown("### ğŸ“– ä¼ è®°å†…å®¹")
                    
                    biography_display = gr.Markdown(
                        value="*ä¼ è®°å°†åœ¨åˆ›ä½œå®Œæˆåæ˜¾ç¤º*",
                        label="ä¼ è®°",
                        show_label=False
                    )
                    
                    with gr.Row():
                        version_dropdown = gr.Dropdown(
                            label="é€‰æ‹©ç‰ˆæœ¬",
                            choices=[],
                            scale=2
                        )
                        word_count = gr.Textbox(
                            label="å­—æ•°",
                            value="0",
                            interactive=False,
                            scale=1
                        )
                    
                    # å¤åˆ¶åŒºåŸŸ
                    copy_textbox = gr.Textbox(
                        label="ğŸ“‹ ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¤åˆ¶ä¼ è®°å†…å®¹",
                        lines=3,
                        visible=True,
                        interactive=True
                    )
                    
                    copy_bio_btn = gr.Button("ğŸ“‹ åŠ è½½åˆ°å¤åˆ¶æ¡†", size="sm")
                
                # Right Column: AgentçŠ¶æ€ + ç³»ç»Ÿæ—¥å¿—
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ¤– AgentçŠ¶æ€")
                    
                    with gr.Accordion("ğŸ§  Coordinatorå†³ç­–", open=True, elem_classes=["agent-coordinator"]):
                        coordinator_output = gr.JSON(label="å†³ç­–è¯¦æƒ…")
                    
                    agent_status = gr.Textbox(
                        label="å½“å‰çŠ¶æ€",
                        lines=2,
                        interactive=False
                    )
                    
                    # Agentå·¥ä½œæˆæœå±•ç¤º
                    with gr.Accordion("ğŸ“š æå–äº‹ä»¶", open=False):
                        extracted_events_display = gr.JSON(label="äº‹ä»¶é”šç‚¹", show_label=False)
                    
                    with gr.Accordion("ğŸ” å†å²ç ”ç©¶", open=False):
                        historical_research_display = gr.Markdown(
                            value="*å°šæœªè¿›è¡Œå†å²ç ”ç©¶*",
                            show_label=False
                        )
                    
                    with gr.Accordion("ğŸ“Š è´¨é‡è¯„ä¼°", open=False):
                        quality_evaluation_display = gr.JSON(label="è¯„ä¼°ç»“æœ", show_label=False)
                    
                    gr.Markdown("### ğŸ“‹ ç³»ç»Ÿæ—¥å¿—")
                    
                    log_display = gr.Textbox(
                        label="æ—¥å¿—",
                        lines=15,
                        max_lines=20,
                        interactive=False,
                        show_label=False
                    )
                    
                    download_log_btn = gr.Button("ğŸ“¥ ä¸‹è½½æ—¥å¿—", size="sm")
                    download_log_file = gr.File(label="ğŸ“¦ ç‚¹å‡»ä¸‹è½½æ—¥å¿—æ–‡ä»¶", visible=False, height=50, interactive=False)
        
        # Hidden status message
        status_message = gr.Textbox(visible=False)
        download_file = gr.File(visible=False)
        copy_output = gr.Textbox(visible=False)
        
        # ====================================================================
        # Event Bindings
        # ====================================================================
        
        # Start new session
        start_btn.click(
            fn=create_new_session,
            inputs=[],
            outputs=[
                session_id_display,
                main_interface,
                start_interface,
                chatbot,
                user_input,
                coordinator_output,
                agent_status,
                biography_display,
                log_display,
                version_dropdown
            ]
        )
        
        # Resume session
        resume_btn.click(
            fn=resume_existing_session,
            inputs=[resume_input],
            outputs=[
                session_id_display,
                main_interface,
                start_interface,
                chatbot,
                biography_display,
                version_dropdown,
                log_display,
                status_message
            ]
        )
        
        # Import session from start interface
        def import_and_show(file_path):
            result = import_session(file_path)
            # resultæ˜¯11ä¸ªå€¼ï¼ˆå¢åŠ äº†3ä¸ªAgentæˆæœæ˜¾ç¤ºï¼‰ï¼Œæˆ‘ä»¬éœ€è¦åœ¨æœ«å°¾æ·»åŠ ç•Œé¢æ˜¾ç¤ºçŠ¶æ€
            return result + (gr.update(visible=True), gr.update(visible=False))
        
        import_start_file.upload(
            fn=import_and_show,
            inputs=[import_start_file],
            outputs=[
                session_id_display,
                chatbot,
                biography_display,
                version_dropdown,
                log_display,
                agent_status,
                coordinator_output,
                status_message,
                extracted_events_display,
                historical_research_display,
                quality_evaluation_display,
                main_interface,
                start_interface
            ]
        )
        
        # Send message - ç‚¹å‡»æŒ‰é’®
        send_btn.click(
            fn=handle_send_message,
            inputs=[user_input, session_id_display, chatbot],
            outputs=[
                chatbot, 
                user_input, 
                coordinator_output, 
                agent_status, 
                log_display,
                extracted_events_display,
                historical_research_display,
                quality_evaluation_display
            ]
        )
        
        # Send message - æŒ‰Enteré”®
        user_input.submit(
            fn=handle_send_message,
            inputs=[user_input, session_id_display, chatbot],
            outputs=[
                chatbot, 
                user_input, 
                coordinator_output, 
                agent_status, 
                log_display,
                extracted_events_display,
                historical_research_display,
                quality_evaluation_display
            ]
        )
        
        # Copy biography
        copy_bio_btn.click(
            fn=copy_to_clipboard,
            inputs=[session_id_display],
            outputs=[copy_textbox]
        )
        
        # å¯¼å…¥ä¼šè¯
        import_session_btn.upload(
            fn=import_session,
            inputs=[import_session_btn],
            outputs=[
                session_id_display,
                chatbot,
                biography_display,
                version_dropdown,
                log_display,
                agent_status,
                coordinator_output,
                status_message,
                extracted_events_display,
                historical_research_display,
                quality_evaluation_display
            ]
        )
        
        # å¯¼å‡ºå®Œæ•´ä¼šè¯
        export_session_btn.click(
            fn=export_session,
            inputs=[session_id_display],
            outputs=[download_session_file]
        )
        
        # Download logs
        download_log_btn.click(
            fn=export_logs,
            inputs=[session_id_display],
            outputs=[download_log_file]
        )
    
    return demo


# ============================================================================
# Main Entry Point
# ============================================================================

def main():
    """Main entry point."""
    import os
    
    port = int(os.getenv("PORT", 7860))
    
    print("ğŸš€ å¯åŠ¨SAGAä¼ è®°ç”Ÿæˆç³»ç»Ÿ...")
    print(f"ğŸ¤– å½“å‰æ¨¡å‹: {settings.default_model}")
    print(f"ğŸ’¾ ä¼šè¯å­˜å‚¨è·¯å¾„: sessions/")
    print(f"ğŸŒ æœåŠ¡ç«¯å£: {port}")
    
    demo = create_gradio_interface()
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=port,
        share=False,
        show_error=True,
        show_api=False
    )


if __name__ == "__main__":
    main()

